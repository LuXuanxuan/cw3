@article{4309979,
  abstract = {This paper proposes a novel approach to pattern analysis through the application of sentence-to-sentence clustering. The method utilizes the distance between corresponding sentences as a measure of similarity between patterns, which allows for the use of any standard clustering criterion once the sentences are extracted and a distance metric is defined. Building upon previous work in statistical pattern recognition, cluster analysis, and information processing, the paper presents an example of the proposed clustering procedure applied to a set of patterns represented as strings. A set of weights is determined via a trial-and-error procedure, and the computer time required for the cluster analysis is reported to be 46 seconds. Overall, this paper contributes to the field of pattern analysis by introducing a new approach that can be applied to a range of applications.},
  author = {Lu, Shin-Yee and Fu, King Sun},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  title = {A Sentence-to-Sentence Clustering Procedure for Pattern Analysis},
  year = {1978},
  volume = {2},
  number = {01},
  pages = {381-389},
  doi = {10.1109/TSMC.1978.4309979},
  series = {Sentence Clustering},
  url = {https://ieeexplore.ieee.org/document/4309999}
}

@inproceedings{7570964,
  author = {Pradip, Kalal Gayatri and Patil, D. R.},
  booktitle = {2016 Symposium on Colossal Data Analysis and Networking (CDAN)},
  title = {Summarization of sentences using fuzzy and hierarchical clustering approach},
  year = {2016},
  volume = {2},
  number = {02},
  pages = {1-7},
  doi = {10.1109/CDAN.2016.7570964},
  abstract = {This paper proposes an approach to improve traditional clustering methods by using fuzzy and hierarchical clustering techniques to summarize sentences. The implementation method involves using a Hierarchical and Fuzzy Relational Eigenvector Centrality-based Clustering Algorithm. The evaluation of the proposed approach is carried out through performance evaluation of the system using different datasets. The paper builds upon Andrew Skabar et al.'s Fuzzy Relational Eigen vector Centrality based Clustering Algorithm (FRECCA) for text documents. Overall, this paper presents a valuable contribution to the field of clustering.},
  series = {Sentence Clustering},
  url = {https://ieeexplore.ieee.org/document/7570964}
}

@inproceedings{8098832,
  author = {Babichev, S. and Lytvynenko, V. and Osypenko, V.},
  booktitle = {2017 12th International Scientific and Technical Conference on Computer Sciences and Information Technologies (CSIT)},
  title = {Implementation of the objective clustering inductive technology based on DBSCAN clustering algorithm},
  year = {2017},
  volume = {2},
  number = {10},
  pages = {479-484},
  doi = {10.1109/STC-CSIT.2017.8098832},
  abstract = {This paper presents the practical application of the DBSCAN clustering algorithm using objective clustering inductive technology. The authors demonstrate that the DBSCAN algorithm is capable of identifying clusters of arbitrary shape even in noisy data. The implementation involves a problem statement, matrix formation, and determination of key parameters using objective clustering inductive technology. Relevant literature includes previous research on clustering algorithms, objective clustering inductive technology, and the DBSCAN algorithm. The experimental evaluation employed real-world datasets with high levels of noise and included comparison with other internal clustering quality criteria such as Calinski-Harabasz criterion and WB-index criterion.},
  series = {Cluster Technology},
  url = {https://ieeexplore.ieee.org/document/8098832}
}

@inproceedings{8752633,
  author = {Hayatin, Nur and Marthasari, Gita Indah and Anggraini, Syadza},
  booktitle = {2018 5th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)},
  title = {Improvement of Cluster Importance Algorithm with Sentence Position for News Summarization},
  year = {2018},
  volume = {2},
  number = {03},
  pages = {483-488},
  doi = {10.1109/EECSI.2018.8752633},
  abstract = {This study proposes a solution for multi-document summarization of news in Bahasa Indonesia by using an improved cluster importance algorithm with sentence position feature. The aim is to efficiently reduce the large dimensions of news articles and extract important information. The method used involves sentence clustering to news sub-topics, weighting each cluster, and sorting the results of the formed clusters. The study builds upon previous work in text summarization, clustering algorithms, and sentence position features. The evaluation of the proposed approach involves testing the summary results generated by the system against manual summaries using ROUGE-N based on equations. Although the data characteristics are not explicitly mentioned in the given pages of the PDF, the study contributes to the field of multi-document summarization and presents a promising approach for Bahasa Indonesia news articles.},
  series = {Sentence Clustering},
  url = {https://ieeexplore.ieee.org/document/8752633}
}

@inproceedings{9141886,
  author = {Wang, Xiaolong and Dong, Xingtong and Chen, Shuxin},
  booktitle = {2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)},
  title = {Text Duplicated-checking Algorithm Implementation Based on Natural Language Semantic Analysis},
  year = {2020},
  volume = {2},
  number = {06},
  pages = {732-735},
  doi = {10.1109/ITOEC49072.2020.9141886},
  abstract = {This paper proposes a new approach to improve text duplication detection using natural language semantic analysis. The authors utilize word2vec technology to construct optimized LDA models that extract topic words and employ cosine similarity to calculate similarity scores. Relevant subject documents are transformed into plain text, preprocessed by segmentation, stop word removal, and quantification, and used as input for the LDA model. The study draws on related work in clustering, probability graph models, and text mining in natural language semantic analysis. Overall, this approach presents a valuable contribution to enhancing the accuracy of text duplication detection through the use of natural language processing techniques.},
  series = {Text Vectorization Technology},
  url = {https://ieeexplore.ieee.org/document/9141886}
}

@inproceedings{9782908,
  author = {Mansour, Ali and Mohammad, Juman and Kravchenko, Yury},
  booktitle = {2022 VI International Conference on Information Technologies in Engineering Education (Inforino)},
  title = {Text Vectorization Method Based on Concept Mining Using Clustering Techniques},
  year = {2022},
  volume = {2},
  number = {05},
  pages = {1-10},
  doi = {10.1109/Inforino53888.2022.9782908},
  abstract = {This paper proposes a new method for text vectorization based on concept mining using clustering techniques to improve accuracy and reduce data dimensionality. The implementation involves building a concepts dictionary, generating document vectors, and clustering them to identify similar documents. Experimental results are provided to evaluate the proposed method and compare it to traditional approaches, contributing to the advancement of the field of text mining and natural language processing.},
  series = {Text Vectorization Technology},
  url = {https://ieeexplore.ieee.org/document/9782908}
}

@inproceedings{9898877,
  author = {Peng, Qian and Kang, Yang and Xuexue, Zhuo},
  booktitle = {2022 International Conference on Information System, Computing and Educational Technology (ICISCET)},
  title = {Website Cluster Technology Based on Cloud Technology and B/S Architecture},
  year = {2022},
  volume = {2},
  number = {9},
  pages = {280-283},
  doi = {10.1109/ICISCET56785.2022.00072},
  abstract = {This paper presents a website cluster technology based on cloud technology and B/S architecture as a solution to challenges encountered in university website construction. The proposed technology improves website security, stability, and sharing capabilities. The paper analyzes system requirements, designs a robust architecture, and establishes a simple website group management platform with complete and flexible functions and low coupling between modules. Core related work discussed in the paper includes cloud computing, website cluster technology, B/S architecture, database management systems, and web development frameworks. The proposed solution can address issues related to inconsistent information resources and data storage structures of university websites. The paper highlights how their proposed solution effectively addresses these problems through the analysis of existing issues},
  series = {Cluster Technology},
  url = {https://ieeexplore.ieee.org/document/9898877}
}

@inproceedings{9984608,
  author = {Rani, Deepa and Kumar, Rajeev and Chauhan, Naveen},
  booktitle = {2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)},
  title = {Study and Comparision of Vectorization Techniques Used in Text Classification},
  year = {2022},
  volume = {2},
  number = {04},
  pages = {1-6},
  doi = {10.1109/ICCCNT54827.2022.9984608},
  abstract = {This paper compares the performance of different vectorization techniques used in text classification for sentiment analysis of customer reviews. The implementation was done using Python with various libraries. The core related work includes Bag-of-Words, TF-IDF, Word2Vec, Doc2Vec, and GloVe used in text classification for sentiment analysis, and the evaluation involves a dataset of 10,000 customer reviews from Amazon products. The study contributes to the field of sentiment analysis by presenting a comparative analysis of various vectorization techniques for text classification.},
  series = {Text Vectorization Technology},
  url = {https://ieeexplore.ieee.org/document/99846083}
}

@article{brown2020language,
  title = {Language models are few-shot learners},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal = {Advances in neural information processing systems},
  volume = {2},
  pages = {1877--1901},
  number = {7},
  year = {2020},
  abstract = {This paper investigates the potential of language models as few-shot learners and demonstrates that scaling up such models can significantly enhance task-agnostic few-shot performance. Specifically, the authors show that their autoregressive language model GPT-3, which contains 175 billion parameters, can perform competitively with prior state-of-the-art fine-tuning approaches even in the few-shot setting. To achieve this, the authors pre-trained their language model on a large corpus of text and fine-tuned it on specific tasks using only a few examples or simple instructions. They evaluated the performance of their model on various NLP tasks and benchmarks, including language modeling, cloze and completion tasks, closed book question answering, and translation. The paper builds upon prior work that has demonstrated the effectiveness of pre-training followed by fine-tuning for improving NLP performance and draws inspiration from human learning abilities, aiming to develop models that can learn from only a few examples or simple instructions. The authors used a large corpus of text for pre-training. They also used various benchmark datasets for evaluating the performance of their model on different NLP tasks.},
  doi = {arXiv:2005.14165},
  series = {OpenAI Api},
  url = {https://arxiv.org/abs/2005.14165}
}

@inproceedings{Radford2018ImprovingLU,
  title = {Improving Language Understanding by Generative Pre-Training},
  author = {Alec Radford and Karthik Narasimhan},
  year = {2018},
  abstract = {This paper proposes a method for improving natural language understanding tasks through generative pre-training of a language model on unlabeled text, followed by discriminative fine-tuning on specific tasks. The authors use the transformer-based language model GPT for pre-training on large amounts of unlabeled text data and fine-tuning on specific natural language understanding tasks using discriminative training with task-specific labeled data. The proposed approach is evaluated on four types of natural language understanding tasks using various benchmark datasets, and the authors report significant improvements in performance compared to other state-of-the-art models. The paper builds upon previous work in natural language processing, including transformer-based models such as BERT and ELMo, and generative pre-training methods like GPT-2. Task-aware input transformations are also introduced to enable effective transfer with minimal modifications to the model architecture. The authors use large amounts of unlabeled text data, including web pages, books, and Wikipedia articles, for pre-training the GPT model, and various labeled datasets for fine-tuning on specific natural language understanding tasks.},
  number = {8},
  volume = {2},
  doi = {10.48550/arXiv:1706.03762},
  series = {OpenAI Api},
  url = {s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf}
}

@article{Beck2016Visual,
  abstract = {Bibiographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.},
  author = {Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel},
  doi = {10.1109/TVCG.2015.2467757},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {type:system, visual_analytics, sparklines, information_retrieval, clustering, literature_browser},
  number = {11},
  publisher = {IEEE},
  series = {TVCG},
  title = {Visual Analysis and Dissemination of Scientific Literature Collections with {SurVis}},
  url = {http://www.visus.uni-stuttgart.de/uploads/tx_vispublications/vast15-survis.pdf},
  volume = {2},
  year = {2016}
}

